import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import mlflow
import os
import time
from datetime import datetime
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import Callback
import plotly.express as px

# ======================================
# PHáº¦N 1: LÃ THUYáº¾T NEURAL NETWORK
# ======================================
def data():
    st.header("MNIST Dataset")
    st.write("""
      **MNIST** lÃ  má»™t trong nhá»¯ng bá»™ dá»¯ liá»‡u ná»•i tiáº¿ng vÃ  phá»• biáº¿n nháº¥t trong cá»™ng Ä‘á»“ng há»c mÃ¡y, 
      Ä‘áº·c biá»‡t lÃ  trong cÃ¡c nghiÃªn cá»©u vá» nháº­n diá»‡n máº«u vÃ  phÃ¢n loáº¡i hÃ¬nh áº£nh.
  
      - Bá»™ dá»¯ liá»‡u bao gá»“m tá»•ng cá»™ng **70.000 áº£nh chá»¯ sá»‘ viáº¿t tay** tá»« **0** Ä‘áº¿n **9**, 
        má»—i áº£nh cÃ³ kÃ­ch thÆ°á»›c **28 x 28 pixel**.
      - Chia thÃ nh:
        - **Training set**: 60.000 áº£nh Ä‘á»ƒ huáº¥n luyá»‡n.
        - **Test set**: 10.000 áº£nh Ä‘á»ƒ kiá»ƒm tra.
      - Má»—i hÃ¬nh áº£nh lÃ  má»™t chá»¯ sá»‘ viáº¿t tay, Ä‘Æ°á»£c chuáº©n hÃ³a vÃ  chuyá»ƒn thÃ nh dáº¡ng grayscale (Ä‘en tráº¯ng).
  
      Dá»¯ liá»‡u nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh nháº­n diá»‡n chá»¯ sá»‘.
      """)

    st.subheader("Má»™t sá»‘ hÃ¬nh áº£nh tá»« MNIST Dataset")
    # st.image("buoi4/img3.png", caption="Má»™t sá»‘ hÃ¬nh áº£nh tá»« MNIST Dataset", use_container_width ="auto")

    st.subheader("á»¨ng dá»¥ng thá»±c táº¿ cá»§a MNIST")
    st.write("""
      Bá»™ dá»¯ liá»‡u MNIST Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng trong nhiá»u á»©ng dá»¥ng nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay, cháº³ng háº¡n nhÆ°:
      - Nháº­n diá»‡n sá»‘ trÃªn cÃ¡c hoÃ¡ Ä‘Æ¡n thanh toÃ¡n, biÃªn lai cá»­a hÃ ng.
      - Xá»­ lÃ½ chá»¯ sá»‘ trÃªn cÃ¡c bÆ°u kiá»‡n gá»­i qua bÆ°u Ä‘iá»‡n.
      - á»¨ng dá»¥ng trong cÃ¡c há»‡ thá»‘ng nháº­n diá»‡n tÃ i liá»‡u tá»± Ä‘á»™ng.
    """)

    st.subheader("VÃ­ dá»¥ vá» cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y vá»›i MNIST")
    st.write("""
      CÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y phá»• biáº¿n Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i bá»™ dá»¯ liá»‡u MNIST bao gá»“m:
      - **Logistic Regression**
      - **Decision Trees**
      - **K-Nearest Neighbors (KNN)**
      - **Support Vector Machines (SVM)**
      - **Convolutional Neural Networks (CNNs)**
    """)

    st.subheader("ğŸ“Š Minh há»a dá»¯ liá»‡u MNIST")

    # Äá»c vÃ  hiá»ƒn thá»‹ áº£nh GIF minh há»a
    # gif_path = "buoi7/g1.gif"  # Thay báº±ng Ä‘Æ°á»ng dáº«n thá»±c táº¿
    # st.image(gif_path, caption="HÃ¬nh áº£nh minh há»a dá»¯ liá»‡u MNIST", use_container_width="auto")

    # MÃ´ táº£ vá» dá»¯ liá»‡u MNIST
    st.write("""
    Dá»¯ liá»‡u MNIST bao gá»“m cÃ¡c hÃ¬nh áº£nh chá»¯ sá»‘ viáº¿t tay cÃ³ kÃ­ch thÆ°á»›c **28x28 pixels**.  
    Má»—i áº£nh lÃ  má»™t **ma tráº­n 28x28**, vá»›i má»—i pixel cÃ³ giÃ¡ trá»‹ tá»« **0 Ä‘áº¿n 255**.  
    Khi Ä‘Æ°a vÃ o mÃ´ hÃ¬nh, áº£nh sáº½ Ä‘Æ°á»£c biáº¿n Ä‘á»•i thÃ nh **784 features (28x28)** Ä‘á»ƒ lÃ m Ä‘áº§u vÃ o cho máº¡ng nÆ¡-ron.  
    MÃ´ hÃ¬nh sá»­ dá»¥ng cÃ¡c lá»›p áº©n Ä‘á»ƒ há»c vÃ  dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c chá»¯ sá»‘ tá»« hÃ¬nh áº£nh.
    """)

    
import streamlit as st

def show_prediction_table():
    st.table({
        "áº¢nh": ["áº¢nh 1", "áº¢nh 2", "áº¢nh 3", "áº¢nh 4", "áº¢nh 5"],
        "Dá»± Ä‘oÃ¡n": [7, 2, 3, 5, 8],
        "XÃ¡c suáº¥t": [0.98, 0.85, 0.96, 0.88, 0.97],
        "GÃ¡n nhÃ£n?": ["âœ…", "âŒ", "âœ…", "âŒ", "âœ…"]
    })

def explain_Pseudo_Labelling():
    
    
    st.markdown("## ğŸ“š LÃ½ thuyáº¿t vá» Pseudo Labelling")
    st.write("""
    **Pseudo Labelling** lÃ  má»™t phÆ°Æ¡ng phÃ¡p semi-supervised learning giÃºp káº¿t há»£p dá»¯ liá»‡u cÃ³ nhÃ£n vÃ  khÃ´ng nhÃ£n Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh. QuÃ¡ trÃ¬nh nÃ y diá»…n ra qua cÃ¡c bÆ°á»›c sau:
    
    1ï¸âƒ£ **Huáº¥n luyá»‡n mÃ´ hÃ¬nh ban Ä‘áº§u** trÃªn má»™t táº­p dá»¯ liá»‡u nhá» (~1% tá»•ng sá»‘ dá»¯ liá»‡u cÃ³ nhÃ£n).  
    2ï¸âƒ£ **Dá»± Ä‘oÃ¡n nhÃ£n** cho cÃ¡c máº«u chÆ°a Ä‘Æ°á»£c gÃ¡n nhÃ£n báº±ng mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n.  
    3ï¸âƒ£ **Lá»c cÃ¡c dá»± Ä‘oÃ¡n cÃ³ Ä‘á»™ tin cáº­y cao** dá»±a trÃªn ngÆ°á»¡ng xÃ¡c suáº¥t (vÃ­ dá»¥: > 0.95).  
    4ï¸âƒ£ **GÃ¡n nhÃ£n giáº£ (Pseudo Labels)** cho cÃ¡c máº«u tin cáº­y.  
    5ï¸âƒ£ **ThÃªm dá»¯ liá»‡u Ä‘Ã£ gÃ¡n nhÃ£n giáº£ vÃ o táº­p train**, má»Ÿ rá»™ng dá»¯ liá»‡u huáº¥n luyá»‡n.  
    6ï¸âƒ£ **Huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh** vá»›i táº­p dá»¯ liá»‡u má»Ÿ rá»™ng (gá»“m dá»¯ liá»‡u ban Ä‘áº§u + dá»¯ liá»‡u cÃ³ nhÃ£n giáº£).  
    7ï¸âƒ£ **Láº·p láº¡i cÃ¡c bÆ°á»›c trÃªn** cho Ä‘áº¿n khi Ä‘áº¡t Ä‘iá»u kiá»‡n dá»«ng (há»™i tá»¥ hoáº·c sá»‘ láº§n láº·p tá»‘i Ä‘a).  
    """)

    # st.image("buoi8/img1.png", caption="CÃ¡c bÆ°á»›c Pseudo Labelling", use_container_width ="auto")

    # VÃ­ dá»¥ minh há»a
    st.markdown("## ğŸ” VÃ­ dá»¥ vá» Pseudo Labelling")
    st.write("""
    Giáº£ sá»­ ta cÃ³ 10.000 áº£nh chá»¯ sá»‘ viáº¿t tay (0-9), nhÆ°ng chá»‰ cÃ³ 1% (100 áº£nh) Ä‘Æ°á»£c gÃ¡n nhÃ£n ban Ä‘áº§u.  
    â†’ CÃ²n láº¡i 9.900 áº£nh khÃ´ng nhÃ£n.
    """)

    st.markdown("### ğŸ **BÆ°á»›c 1: Huáº¥n luyá»‡n mÃ´ hÃ¬nh ban Ä‘áº§u**")
    st.write("""
    - MÃ´ hÃ¬nh Ä‘Æ°á»£c train trÃªn 100 áº£nh cÃ³ nhÃ£n.  
    - Do dá»¯ liá»‡u Ã­t, mÃ´ hÃ¬nh cÃ³ Ä‘á»™ chÃ­nh xÃ¡c tháº¥p.  
    """)

    st.markdown("### ğŸ§  **BÆ°á»›c 2: Dá»± Ä‘oÃ¡n nhÃ£n cho dá»¯ liá»‡u chÆ°a gÃ¡n nhÃ£n**")
    st.write("""
    - Cháº¡y mÃ´ hÃ¬nh trÃªn 9.900 áº£nh chÆ°a gÃ¡n nhÃ£n.  
    - Dá»± Ä‘oÃ¡n vÃ  tÃ­nh xÃ¡c suáº¥t cho má»—i áº£nh.  
    """)
    
    show_prediction_table()  # Hiá»ƒn thá»‹ báº£ng dá»± Ä‘oÃ¡n máº«u

    st.markdown("### ğŸ”¬ **BÆ°á»›c 3: Lá»c dá»¯ liá»‡u cÃ³ Ä‘á»™ tin cáº­y cao**")
    st.write("""
    - Chá»‰ chá»n nhá»¯ng áº£nh cÃ³ xÃ¡c suáº¥t dá»± Ä‘oÃ¡n cao hÆ¡n ngÆ°á»¡ng tin cáº­y (vÃ­ dá»¥: 0.95).  
    -áº¢nh 1, 3, 5 sáº½ Ä‘Æ°á»£c gÃ¡n nhÃ£n giáº£.
    -áº¢nh 2, 4 bá»‹ bá» qua vÃ¬ mÃ´ hÃ¬nh khÃ´ng tá»± tin.
    - Nhá»¯ng áº£nh Ä‘áº¡t tiÃªu chuáº©n sáº½ Ä‘Æ°á»£c gÃ¡n nhÃ£n giáº£.  
    - áº¢nh cÃ³ Ä‘á»™ tin cáº­y tháº¥p sáº½ bá»‹ loáº¡i bá».  
    """)

    st.markdown("### ğŸ·ï¸ **BÆ°á»›c 4: GÃ¡n nhÃ£n giáº£ cho cÃ¡c dá»± Ä‘oÃ¡n tin cáº­y**")
    st.write("""
    - CÃ¡c máº«u cÃ³ Ä‘á»™ tin cáº­y cao Ä‘Æ°á»£c gÃ¡n nhÃ£n theo káº¿t quáº£ dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh.  
    - vÃ­ dá»¥ 500 Ä‘Æ°á»£c áº£nh
    """)

    st.markdown("### ğŸ“‚ **BÆ°á»›c 5: ThÃªm dá»¯ liá»‡u gÃ¡n nhÃ£n giáº£ vÃ o táº­p train**")
    st.write("""
    - Táº­p train má»›i = dá»¯ liá»‡u ban Ä‘áº§u + cÃ¡c áº£nh cÃ³ nhÃ£n giáº£.  
    - VÃ­ dá»¥: tá»« 100 áº£nh cÃ³ nhÃ£n ban Ä‘áº§u, ta cÃ³ thá»ƒ má»Ÿ rá»™ng lÃªn 600 áº£nh sau khi thÃªm nhÃ£n giáº£.  
    """)

    st.markdown("### ğŸ”„ **BÆ°á»›c 6: Huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh vá»›i táº­p dá»¯ liá»‡u má»Ÿ rá»™ng**")
    st.write("""
    - Huáº¥n luyá»‡n láº¡i mÃ´ hÃ¬nh trÃªn táº­p dá»¯ liá»‡u má»›i.  
    - MÃ´ hÃ¬nh sáº½ há»c thÃªm tá»« dá»¯ liá»‡u má»›i vÃ  dáº§n cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c.  
    """)

    st.markdown("### ğŸ” **BÆ°á»›c 7: Láº·p láº¡i quÃ¡ trÃ¬nh Ä‘áº¿n khi há»™i tá»¥**")
    st.write("""
    - QuÃ¡ trÃ¬nh tiáº¿p tá»¥c cho Ä‘áº¿n khi Ä‘áº¡t Ä‘iá»u kiá»‡n dá»«ng:  
      - Äáº¡t sá»‘ láº§n láº·p tá»‘i Ä‘a  
      - MÃ´ hÃ¬nh khÃ´ng cáº£i thiá»‡n thÃªm  
    """)

    st.markdown("## ğŸ¯ **Káº¿t quáº£ cuá»‘i cÃ¹ng**")
    st.write("""
    - Ban Ä‘áº§u chá»‰ cÃ³ 100 áº£nh cÃ³ nhÃ£n.  
    - Sau vÃ i vÃ²ng láº·p, mÃ´ hÃ¬nh cÃ³ thá»ƒ tá»± gÃ¡n nhÃ£n cho hÃ ng ngÃ n áº£nh.  
    - Äá»™ chÃ­nh xÃ¡c tÄƒng dáº§n theo má»—i láº§n huáº¥n luyá»‡n láº¡i.  
    """)

    st.success("âœ… Pseudo Labelling giÃºp táº­n dá»¥ng dá»¯ liá»‡u chÆ°a cÃ³ nhÃ£n Ä‘á»ƒ cáº£i thiá»‡n mÃ´ hÃ¬nh AI má»™t cÃ¡ch hiá»‡u quáº£!")






import streamlit as st
import numpy as np
import time
import mlflow
import mlflow.keras
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split, StratifiedKFold
from mlflow.models.signature import infer_signature

# Load dá»¯ liá»‡u MNIST
def load_mnist_data():
    mnist = fetch_openml('mnist_784', version=1, as_frame=False)
    x, y = mnist.data, mnist.target.astype(np.uint8)
    return x / 255.0, y  # Chuáº©n hÃ³a dá»¯ liá»‡u

def split_data():
    st.title("ğŸ“Œ Chia dá»¯ liá»‡u Train/Test")
    
    # Äá»c dá»¯ liá»‡u
    X, y = load_mnist_data()
    total_samples = X.shape[0] 
    
    # Thanh kÃ©o chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train
    num_samples = st.slider("ğŸ“Œ Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ huáº¥n luyá»‡n:", 1000, total_samples, 10000)
    num_samples =num_samples -10
    # Thanh kÃ©o chá»n tá»· lá»‡ Train/Test
    test_size = st.slider("ğŸ“Œ Chá»n % dá»¯ liá»‡u Test", 10, 50, 20)
    train_size = 100 - test_size
    val_size = st.slider("ğŸ“Œ Chá»n % dá»¯ liá»‡u Validation (trong Train)", 0, 50, 15)
    
    st.write(f"ğŸ“Œ **Tá»· lá»‡ phÃ¢n chia:** Test={test_size}%, Validation={val_size}%, Train={train_size - val_size}%")
    
    if st.button("âœ… XÃ¡c nháº­n & LÆ°u"):
        X_selected, _, y_selected, _ = train_test_split(X, y, train_size=num_samples, stratify=y, random_state=42)
        X_train_full, X_test, y_train_full, y_test = train_test_split(X_selected, y_selected, test_size=test_size/100, stratify=y_selected, random_state=42)
        X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=val_size / (100 - test_size), stratify=y_train_full, random_state=42)
        
        # LÆ°u vÃ o session_state
        st.session_state.update({
            "X_train": X_train, "X_val": X_val, "X_test": X_test,
            "y_train": y_train, "y_val": y_val, "y_test": y_test
        })
        
        summary_df = pd.DataFrame({"Táº­p dá»¯ liá»‡u": ["Train", "Validation", "Test"], "Sá»‘ lÆ°á»£ng máº«u": [X_train.shape[0], X_val.shape[0], X_test.shape[0]]})
        st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh cÃ´ng!")
        st.table(summary_df)

def thi_nghiem():
    num = 0
    if "X_train" not in st.session_state:
        st.error("âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u! HÃ£y chia dá»¯ liá»‡u trÆ°á»›c.")
        return

    X_train, X_val, X_test = [st.session_state[k].reshape(-1, 28 * 28) / 255.0 for k in ["X_train", "X_val", "X_test"]]
    y_train, y_val, y_test = [st.session_state[k] for k in ["y_train", "y_val", "y_test"]]

    k_folds = st.slider("Sá»‘ fold cho Cross-Validation:", 3, 10, 5)
    num_layers = st.slider("Sá»‘ lá»›p áº©n:", 1, 5, 2)
    num_neurons = st.slider("Sá»‘ neuron má»—i lá»›p:", 32, 512, 128, 32)
    activation = st.selectbox("HÃ m kÃ­ch hoáº¡t:", ["relu", "sigmoid", "tanh"])
    optimizer = st.selectbox("Optimizer:", ["adam", "sgd", "rmsprop"])
    epochs = st.slider("ğŸ•° Sá»‘ epochs:", min_value=1, max_value=50, value=20, step=1)
    learning_rate = st.slider("âš¡ Tá»‘c Ä‘á»™ há»c (Learning Rate):", min_value=1e-5, max_value=1e-1, value=1e-3, step=1e-5, format="%.5f")
    labeled_ratio = st.slider("ğŸ“Š Tá»‰ lá»‡ dá»¯ liá»‡u cÃ³ nhÃ£n ban Ä‘áº§u (%):", min_value=1, max_value=20, value=1, step=1)
    max_iterations = st.slider("ğŸ”„ Sá»‘ láº§n láº·p tá»‘i Ä‘a cá»§a Pseudo-Labeling:", min_value=1, max_value=10, value=3, step=1)
    confidence_threshold = st.slider("âœ… NgÆ°á»¡ng tin cáº­y Pseudo Labeling (%):", min_value=50, max_value=99, value=95, step=1) / 100.0

    loss_fn = "sparse_categorical_crossentropy"
    run_name = st.text_input("ğŸ”¹ Nháº­p tÃªn Run:", "Default_Run")
    st.session_state['run_name'] = run_name

    if st.button("ğŸš€ Huáº¥n luyá»‡n mÃ´ hÃ¬nh"):
        with st.spinner("Äang huáº¥n luyá»‡n..."):
            mlflow.start_run(run_name=run_name)
            mlflow.log_params({
                "num_layers": num_layers,
                "num_neurons": num_neurons,
                "activation": activation,
                "optimizer": optimizer,
                "learning_rate": learning_rate,
                "k_folds": k_folds,
                "epochs": epochs,
                "labeled_ratio": labeled_ratio,
                "max_iterations": max_iterations,
                "confidence_threshold": confidence_threshold
            })

            num_labeled = int(len(X_train) * labeled_ratio / 100)
            labeled_idx = np.random.choice(len(X_train), num_labeled, replace=False)
            unlabeled_idx = np.setdiff1d(np.arange(len(X_train)), labeled_idx)

            X_labeled, y_labeled = X_train[labeled_idx], y_train[labeled_idx]
            X_unlabeled = X_train[unlabeled_idx]

            total_pseudo_labels = 0  # Tá»•ng sá»‘ nhÃ£n giáº£ Ä‘Æ°á»£c thÃªm vÃ o

            for iteration in range(max_iterations):
                kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)
                accuracies, losses = [], []
                training_progress = st.progress(0)
                training_status = st.empty()

                num = 0
                total_steps = k_folds * max_iterations

                for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_labeled, y_labeled)):
                    X_k_train, X_k_val = X_labeled[train_idx], X_labeled[val_idx]
                    y_k_train, y_k_val = y_labeled[train_idx], y_labeled[val_idx]

                    model = keras.Sequential([
                        layers.Input(shape=(X_k_train.shape[1],))
                    ] + [
                        layers.Dense(num_neurons, activation=activation) for _ in range(num_layers)
                    ] + [
                        layers.Dense(10, activation="softmax")
                    ])

                    if optimizer == "adam":
                        opt = keras.optimizers.Adam(learning_rate=learning_rate)
                    elif optimizer == "sgd":
                        opt = keras.optimizers.SGD(learning_rate=learning_rate)
                    else:
                        opt = keras.optimizers.RMSprop(learning_rate=learning_rate)

                    model.compile(optimizer=opt, loss=loss_fn, metrics=["accuracy"])

                    start_time = time.time()
                    history = model.fit(X_k_train, y_k_train, epochs=epochs, validation_data=(X_k_val, y_k_val), verbose=0)
                    elapsed_time = time.time() - start_time

                    accuracies.append(history.history["val_accuracy"][-1])
                    losses.append(history.history["val_loss"][-1])
                    num += 1
                    progress_percent = int((num / k_folds) * 100)

                    training_progress.progress(progress_percent)
                    training_status.text(f"â³ Äang huáº¥n luyá»‡n... {progress_percent}%")

                avg_val_accuracy = np.mean(accuracies)
                avg_val_loss = np.mean(losses)

                mlflow.log_metrics({
                    "avg_val_accuracy": avg_val_accuracy,
                    "avg_val_loss": avg_val_loss,
                    "elapsed_time": elapsed_time
                })

                pseudo_preds = model.predict(X_unlabeled)
                pseudo_labels = np.argmax(pseudo_preds, axis=1)
                confidence_scores = np.max(pseudo_preds, axis=1)
                confident_mask = confidence_scores > confidence_threshold

                num_pseudo_added = np.sum(confident_mask)
                total_pseudo_labels += num_pseudo_added

                X_labeled = np.concatenate([X_labeled, X_unlabeled[confident_mask]])
                y_labeled = np.concatenate([y_labeled, pseudo_labels[confident_mask]])
                X_unlabeled = X_unlabeled[~confident_mask]

                # ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p validation vÃ  test sau khi gÃ¡n nhÃ£n giáº£
                val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)
                test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)

                st.write(f"ğŸ“¢ **VÃ²ng láº·p {iteration+1}:**")
                st.write(f"- Sá»‘ pseudo labels má»›i thÃªm: {num_pseudo_added}")
                st.write(f"- Tá»•ng sá»‘ pseudo labels: {total_pseudo_labels}")
                st.write(f"- Sá»‘ lÆ°á»£ng dá»¯ liá»‡u chÆ°a gÃ¡n nhÃ£n cÃ²n láº¡i: {len(X_unlabeled)}")
                st.write(f"- ğŸ”¥ **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p validation:** {val_accuracy:.4f}")
                st.write(f"- ğŸš€ **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p test:** {test_accuracy:.4f}")
                st.write("---")

                # LÆ°u Ä‘á»™ chÃ­nh xÃ¡c vÃ o MLflow Ä‘á»ƒ theo dÃµi
                mlflow.log_metrics({
                    f"val_accuracy_iter_{iteration+1}": val_accuracy,
                    f"test_accuracy_iter_{iteration+1}": test_accuracy
                })
                if len(X_unlabeled) == 0:
                    break

            test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
            mlflow.log_metrics({"test_accuracy": test_accuracy, "test_loss": test_loss})
            mlflow.end_run()
            st.session_state["trained_model"] = model
            training_progress.progress(100)
            training_status.text("âœ… Huáº¥n luyá»‡n hoÃ n táº¥t!")

            st.success(f"âœ… Huáº¥n luyá»‡n hoÃ n táº¥t!")
            st.write(f"ğŸ“Š **Äá»™ chÃ­nh xÃ¡c trung bÃ¬nh trÃªn táº­p validation:** {avg_val_accuracy:.4f}")
            st.write(f"ğŸ“Š **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p test:** {test_accuracy:.4f}")
            st.success(f"âœ… ÄÃ£ log dá»¯ liá»‡u cho **{st.session_state['run_name']}** trong MLflow! ğŸš€")
            st.markdown(f"ğŸ”— [Truy cáº­p MLflow UI]({st.session_state['mlflow_url']})")


                
            
            

import streamlit as st
import numpy as np
import joblib
import random
import pandas as pd
import time
from PIL import Image
from streamlit_drawable_canvas import st_canvas
from tensorflow.keras.models import load_model

def preprocess_canvas_image(canvas_result):
    """Chuyá»ƒn Ä‘á»•i áº£nh tá»« canvas sang Ä‘á»‹nh dáº¡ng phÃ¹ há»£p Ä‘á»ƒ dá»± Ä‘oÃ¡n."""
    if canvas_result.image_data is None:
        return None
    img = canvas_result.image_data[:, :, :3]  # Chá»‰ láº¥y 3 kÃªnh RGB
    img = Image.fromarray(img).convert("L").resize((28, 28))  # Chuyá»ƒn sang grayscale, resize vá» 28x28
    img = np.array(img) / 255.0  # Chuáº©n hÃ³a vá» [0,1]
    img = img.reshape(1, -1)  # ÄÆ°a vá» dáº¡ng vector giá»‘ng nhÆ° trong `thi_nghiem()`
    return img

def du_doan():
    st.header("âœï¸ Váº½ sá»‘ Ä‘á»ƒ dá»± Ä‘oÃ¡n")

    # ğŸ“¥ Load mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
    if "trained_model" in st.session_state:
        model = st.session_state["trained_model"]
        st.success("âœ… ÄÃ£ sá»­ dá»¥ng mÃ´ hÃ¬nh vá»«a huáº¥n luyá»‡n!")
    else:
        st.error("âš ï¸ ChÆ°a cÃ³ mÃ´ hÃ¬nh! HÃ£y huáº¥n luyá»‡n trÆ°á»›c.")


    # ğŸ†• Cáº­p nháº­t key cho canvas khi nháº¥n "Táº£i láº¡i"
    if "key_value" not in st.session_state:
        st.session_state.key_value = str(random.randint(0, 1000000))  

    if st.button("ğŸ”„ Táº£i láº¡i náº¿u khÃ´ng tháº¥y canvas"):
        st.session_state.key_value = str(random.randint(0, 1000000))  

    # âœï¸ Váº½ sá»‘
    canvas_result = st_canvas(
        fill_color="black",
        stroke_width=10,
        stroke_color="white",
        background_color="black",
        height=150,
        width=150,
        drawing_mode="freedraw",
        key=st.session_state.key_value,
        update_streamlit=True
    )

    if st.button("Dá»± Ä‘oÃ¡n sá»‘"):
        img = preprocess_canvas_image(canvas_result)

        if img is not None:
            st.image(Image.fromarray((img.reshape(28, 28) * 255).astype(np.uint8)), caption="áº¢nh sau xá»­ lÃ½", width=100)

            # Dá»± Ä‘oÃ¡n sá»‘
            prediction = model.predict(img)
            predicted_number = np.argmax(prediction, axis=1)[0]
            max_confidence = np.max(prediction)

            st.subheader(f"ğŸ”¢ Dá»± Ä‘oÃ¡n: {predicted_number}")
            st.write(f"ğŸ“Š Má»©c Ä‘á»™ tin cáº­y: {max_confidence:.2%}")

            # Hiá»ƒn thá»‹ báº£ng confidence score
            prob_df = pd.DataFrame(prediction.reshape(1, -1), columns=[str(i) for i in range(10)]).T
            prob_df.columns = ["Má»©c Ä‘á»™ tin cáº­y"]
            st.bar_chart(prob_df)

        else:
            st.error("âš ï¸ HÃ£y váº½ má»™t sá»‘ trÆ°á»›c khi báº¥m Dá»± Ä‘oÃ¡n!")

    
from datetime import datetime    
import streamlit as st
import mlflow
from datetime import datetime

def show_experiment_selector():
    st.title("ğŸ“Š MLflow")
    
    # Káº¿t ná»‘i vá»›i DAGsHub MLflow Tracking
    mlflow.set_tracking_uri("https://dagshub.com/huydfdcv/my-first-repo.mlflow")
    
    # Láº¥y danh sÃ¡ch táº¥t cáº£ experiments
    experiment_name = "Neural_Network"
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"âŒ Experiment '{experiment_name}' khÃ´ng tá»“n táº¡i!")
        return

    st.subheader(f"ğŸ“Œ Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tráº¡ng thÃ¡i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**Vá»‹ trÃ­ lÆ°u trá»¯:** {selected_experiment.artifact_location}")

    # Láº¥y danh sÃ¡ch runs trong experiment
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("âš  KhÃ´ng cÃ³ runs nÃ o trong experiment nÃ y.")
        return

    st.write("### ğŸƒâ€â™‚ï¸ CÃ¡c Runs gáº§n Ä‘Ã¢y:")
    
    # Láº¥y danh sÃ¡ch run_name tá»« params
    run_info = []
    for _, run in runs.iterrows():
        run_id = run["run_id"]
        run_tags = mlflow.get_run(run_id).data.tags
        run_name = run_tags.get("mlflow.runName", f"Run {run_id[:8]}")  # Láº¥y tá»« tags
        run_info.append((run_name, run_id))
    
    # Táº¡o dictionary Ä‘á»ƒ map run_name -> run_id
    run_name_to_id = dict(run_info)
    run_names = list(run_name_to_id.keys())
    
    # Chá»n run theo run_name
    selected_run_name = st.selectbox("ğŸ” Chá»n má»™t run:", run_names)
    selected_run_id = run_name_to_id[selected_run_name]

    # Hiá»ƒn thá»‹ thÃ´ng tin chi tiáº¿t cá»§a run Ä‘Æ°á»£c chá»n
    selected_run = mlflow.get_run(selected_run_id)

    if selected_run:
        st.subheader(f"ğŸ“Œ ThÃ´ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tráº¡ng thÃ¡i:** {selected_run.info.status}")
        
        start_time_ms = selected_run.info.start_time  # Thá»i gian lÆ°u dÆ°á»›i dáº¡ng milliseconds
        if start_time_ms:
            start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S")
        else:
            start_time = "KhÃ´ng cÃ³ thÃ´ng tin"
        
        st.write(f"**Thá»i gian cháº¡y:** {start_time}")

        # Hiá»ƒn thá»‹ thÃ´ng sá»‘ Ä‘Ã£ log
        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### âš™ï¸ Parameters:")
            st.json(params)

        if metrics:
            st.write("### ğŸ“Š Metrics:")
            st.json(metrics)

        # Kiá»ƒm tra vÃ  hiá»ƒn thá»‹ dataset artifact
        dataset_path = f"{selected_experiment.artifact_location}/{selected_run_id}/artifacts/dataset.npy"
        st.write("### ğŸ“‚ Dataset:")
        st.write(f"ğŸ“¥ [Táº£i dataset]({dataset_path})")
    else:
        st.warning("âš  KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin cho run nÃ y.")

        
        
        
          
import mlflow
import os
from mlflow.tracking import MlflowClient
def Neural_Network():
    #st.title("ğŸš€ MLflow DAGsHub Tracking vá»›i Streamlit")
    
    if "mlflow_initialized" not in st.session_state:   
        
        DAGSHUB_MLFLOW_URI = "https://dagshub.com/huydfdcv/my-first-repo.mlflow"
        st.session_state['mlflow_url']=DAGSHUB_MLFLOW_URI
        os.environ["MLFLOW_TRACKING_USERNAME"] = "huydfdcv"
        os.environ["MLFLOW_TRACKING_PASSWORD"] = "2CaXhRNYabm9fN3"
        st.session_state.mlflow_initialized = True
        mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
        mlflow.set_experiment("MNIST Pseudo Labelling")
                
    
    
    # Táº¡o cÃ¡c tab vá»›i tiÃªu Ä‘á» tÆ°Æ¡ng á»©ng
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“˜ LÃ½ thuyáº¿t NEURAL NETWORK",
        "ğŸ“Š Máº«u dá»¯ liá»‡u",
        "ğŸ§  Huáº¥n luyá»‡n",
        "ğŸ–¥ï¸ DEMO",
        "ğŸ”¥ MLflow"
    ])

    # Ná»™i dung tá»«ng tab
    with tab1:
        explain_Pseudo_Labelling()

    with tab2:
        data()

    with tab3:
        st.title("ğŸ§  Huáº¥n luyá»‡n Neural Network trÃªn MNIST")
        split_data()
        thi_nghiem()

    with tab4:
        du_doan()

    with tab5:
        show_experiment_selector()



if __name__ == "__main__":
    Neural_Network()