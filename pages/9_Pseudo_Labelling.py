import streamlit as st
import numpy as np
import mlflow
import os
import time
from datetime import datetime
import time
import mlflow.keras
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split, StratifiedKFold
from mlflow.models.signature import infer_signature
import random
import pandas as pd
import time
from PIL import Image
from streamlit_drawable_canvas import st_canvas
import os
# Load dá»¯ liá»‡u MNIST
def load_mnist_data():
    X = np.load("X.npy")
    y = np.load("y.npy")
    return X, y

def split_data():
    st.title("ğŸ“Œ Chia dá»¯ liá»‡u Train/Test")
    
    # Äá»c dá»¯ liá»‡u
    X, y = load_mnist_data()
    total_samples = X.shape[0] 
    
    # Thanh kÃ©o chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train
    num_samples = st.slider("ğŸ“Œ Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ huáº¥n luyá»‡n:", 1000, total_samples, 10000)
    num_samples =num_samples -10
    # Thanh kÃ©o chá»n tá»· lá»‡ Train/Test
    test_size = st.slider("ğŸ“Œ Chá»n % dá»¯ liá»‡u Test", 10, 50, 20)
    train_size = 100 - test_size
    
    st.write(f"ğŸ“Œ **Tá»· lá»‡ phÃ¢n chia:** Test={test_size}%, Train={train_size}%")
    
    if st.button("âœ… XÃ¡c nháº­n & LÆ°u"):
        X_selected, _, y_selected, _ = train_test_split(X, y, train_size=num_samples, stratify=y, random_state=42)
        X_train, X_test, y_train, y_test = train_test_split(X_selected, y_selected, test_size=test_size/100, stratify=y_selected, random_state=42)
        
        # LÆ°u vÃ o session_state
        st.session_state.update({
            "X_train": X_train, "X_test": X_test,
            "y_train": y_train, "y_test": y_test
        })
        
        summary_df = pd.DataFrame({"Táº­p dá»¯ liá»‡u": ["Train", "Test"], "Sá»‘ lÆ°á»£ng máº«u": [X_train.shape[0], X_test.shape[0]]})
        st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh cÃ´ng!")
        st.table(summary_df)

def thi_nghiem():
    num = 0
    if "X_train" not in st.session_state:
        st.error("âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u! HÃ£y chia dá»¯ liá»‡u trÆ°á»›c.")
        return

    X_train, X_test = [st.session_state[k].reshape(-1, 28 * 28) / 255.0 for k in ["X_train", "X_test"]]
    y_train, y_test = [st.session_state[k] for k in ["y_train", "y_test"]]
    st.title(f"Chá»n tham sá»‘ cho Neural Network ")
    k_folds = st.slider("Sá»‘ fold cho Cross-Validation:", 3, 10, 5)
    num_layers = st.slider("Sá»‘ lá»›p áº©n:", 1, 5, 2)
    num_neurons = st.slider("Sá»‘ neuron má»—i lá»›p:", 32, 512, 128, 32)
    activation = st.selectbox("HÃ m kÃ­ch hoáº¡t:", ["relu", "sigmoid", "tanh"])
    optimizer = st.selectbox("Optimizer:", ["adam", "sgd", "rmsprop"])
    epochs = st.slider("ğŸ•° Sá»‘ epochs:", min_value=1, max_value=50, value=20, step=1)
    learning_rate = st.slider("âš¡ Tá»‘c Ä‘á»™ há»c (Learning Rate):", min_value=1e-5, max_value=1e-1, value=1e-3, step=1e-5, format="%.5f")
    
    st.title(f"Chá»n tham sá»‘ cho Pseudo Labelling ")
    labeled_ratio = st.slider("ğŸ“Š Tá»‰ lá»‡ dá»¯ liá»‡u cÃ³ nhÃ£n ban Ä‘áº§u (%):", min_value=1, max_value=20, value=1, step=1)
    max_iterations = st.slider("ğŸ”„ Sá»‘ láº§n láº·p tá»‘i Ä‘a cá»§a Pseudo-Labeling:", min_value=1, max_value=10, value=3, step=1)
    confidence_threshold = st.slider("âœ… NgÆ°á»¡ng tin cáº­y Pseudo Labeling (%):", min_value=50, max_value=99, value=95, step=1) / 100.0

    loss_fn = "sparse_categorical_crossentropy"
    run_name = st.text_input("ğŸ”¹ Nháº­p tÃªn Run:", "Default_Run")
    st.session_state['run_name'] = run_name

    if st.button("ğŸš€ Huáº¥n luyá»‡n mÃ´ hÃ¬nh"):
        with st.spinner("Äang huáº¥n luyá»‡n..."):
            mlflow.start_run(run_name=run_name)
            mlflow.log_params({
                "num_layers": num_layers,
                "num_neurons": num_neurons,
                "activation": activation,
                "optimizer": optimizer,
                "learning_rate": learning_rate,
                "k_folds": k_folds,
                "epochs": epochs,
                "labeled_ratio": labeled_ratio,
                "max_iterations": max_iterations,
                "confidence_threshold": confidence_threshold
            })

            num_labeled = int(len(X_train) * labeled_ratio / 100)
            labeled_idx = np.random.choice(len(X_train), num_labeled, replace=False)
            unlabeled_idx = np.setdiff1d(np.arange(len(X_train)), labeled_idx)

            X_labeled, y_labeled = X_train[labeled_idx], y_train[labeled_idx]
            X_unlabeled = X_train[unlabeled_idx]

            total_pseudo_labels = 0  # Tá»•ng sá»‘ nhÃ£n giáº£ Ä‘Æ°á»£c thÃªm vÃ o

            for iteration in range(max_iterations):
                kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)
                accuracies, losses = [], []
                training_progress = st.progress(0)
                training_status = st.empty()

                num = 0
                total_steps = k_folds * max_iterations

                for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_labeled, y_labeled)):
                    X_k_train, X_k_val = X_labeled[train_idx], X_labeled[val_idx]
                    y_k_train, y_k_val = y_labeled[train_idx], y_labeled[val_idx]

                    model = keras.Sequential([
                        layers.Input(shape=(X_k_train.shape[1],))
                    ] + [
                        layers.Dense(num_neurons, activation=activation) for _ in range(num_layers)
                    ] + [
                        layers.Dense(10, activation="softmax")
                    ])

                    if optimizer == "adam":
                        opt = keras.optimizers.Adam(learning_rate=learning_rate)
                    elif optimizer == "sgd":
                        opt = keras.optimizers.SGD(learning_rate=learning_rate)
                    else:
                        opt = keras.optimizers.RMSprop(learning_rate=learning_rate)

                    model.compile(optimizer=opt, loss=loss_fn, metrics=["accuracy"])

                    start_time = time.time()
                    history = model.fit(X_k_train, y_k_train, epochs=epochs, validation_data=(X_k_val, y_k_val), verbose=0)
                    elapsed_time = time.time() - start_time

                    accuracies.append(history.history["val_accuracy"][-1])
                    losses.append(history.history["val_loss"][-1])
                    num += 1
                    progress_percent = int((num / k_folds) * 100)

                    training_progress.progress(progress_percent)
                    training_status.text(f"â³ Äang huáº¥n luyá»‡n... {progress_percent}%")

                avg_val_accuracy = np.mean(accuracies)
                avg_val_loss = np.mean(losses)

                mlflow.log_metrics({
                    "avg_val_accuracy": avg_val_accuracy,
                    "avg_val_loss": avg_val_loss,
                    "elapsed_time": elapsed_time
                })

                pseudo_preds = model.predict(X_unlabeled)
                pseudo_labels = np.argmax(pseudo_preds, axis=1)
                confidence_scores = np.max(pseudo_preds, axis=1)
                confident_mask = confidence_scores > confidence_threshold

                num_pseudo_added = np.sum(confident_mask)
                total_pseudo_labels += num_pseudo_added

                X_labeled = np.concatenate([X_labeled, X_unlabeled[confident_mask]])
                y_labeled = np.concatenate([y_labeled, pseudo_labels[confident_mask]])
                X_unlabeled = X_unlabeled[~confident_mask]

                # ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p validation vÃ  test sau khi gÃ¡n nhÃ£n giáº£
                #val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)
                test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)

                st.write(f"ğŸ“¢ **VÃ²ng láº·p {iteration+1}:**")
                st.write(f"- Sá»‘ pseudo labels má»›i thÃªm: {num_pseudo_added}")
                st.write(f"- Tá»•ng sá»‘ pseudo labels: {total_pseudo_labels}")
                st.write(f"- Sá»‘ lÆ°á»£ng dá»¯ liá»‡u chÆ°a gÃ¡n nhÃ£n cÃ²n láº¡i: {len(X_unlabeled)}")
                # st.write(f"- ğŸ”¥ **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p validation:** {val_accuracy:.4f}")
                st.write(f"- ğŸš€ **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p test:** {test_accuracy:.4f}")
                st.write("---")

                # LÆ°u Ä‘á»™ chÃ­nh xÃ¡c vÃ o MLflow Ä‘á»ƒ theo dÃµi
                mlflow.log_metrics({
                    # f"val_accuracy_iter_{iteration+1}": val_accuracy,
                    f"test_accuracy_iter_{iteration+1}": test_accuracy
                })
                if len(X_unlabeled) == 0:
                    break

            test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
            mlflow.log_metrics({"test_accuracy": test_accuracy, "test_loss": test_loss})
            mlflow.end_run()
            st.session_state["trained_model"] = model
            training_progress.progress(100)
            training_status.text("âœ… Huáº¥n luyá»‡n hoÃ n táº¥t!")

            st.success(f"âœ… Huáº¥n luyá»‡n hoÃ n táº¥t!")
            st.write(f"ğŸ“Š **Äá»™ chÃ­nh xÃ¡c trung bÃ¬nh trÃªn táº­p validation:** {avg_val_accuracy:.4f}")
            st.write(f"ğŸ“Š **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p test:** {test_accuracy:.4f}")
            st.success(f"âœ… ÄÃ£ log dá»¯ liá»‡u cho **{st.session_state['run_name']}** trong MLflow! ğŸš€")
            st.markdown(f"ğŸ”— [Truy cáº­p MLflow UI]({st.session_state['mlflow_url']})")
def preprocess_canvas_image(canvas_result):
    """Chuyá»ƒn Ä‘á»•i áº£nh tá»« canvas sang Ä‘á»‹nh dáº¡ng phÃ¹ há»£p Ä‘á»ƒ dá»± Ä‘oÃ¡n."""
    if canvas_result.image_data is None:
        return None
    img = canvas_result.image_data[:, :, :3]  # Chá»‰ láº¥y 3 kÃªnh RGB
    img = Image.fromarray(img).convert("L").resize((28, 28))  # Chuyá»ƒn sang grayscale, resize vá» 28x28
    img = np.array(img) / 255.0  # Chuáº©n hÃ³a vá» [0,1]
    img = img.reshape(1, -1)  # ÄÆ°a vá» dáº¡ng vector giá»‘ng nhÆ° trong `thi_nghiem()`
    return img

def du_doan():
    st.header("âœï¸ Váº½ sá»‘ Ä‘á»ƒ dá»± Ä‘oÃ¡n")

    # ğŸ“¥ Load mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
    if "trained_model" in st.session_state:
        model = st.session_state["trained_model"]
        st.success("âœ… ÄÃ£ sá»­ dá»¥ng mÃ´ hÃ¬nh vá»«a huáº¥n luyá»‡n!")
    else:
        st.error("âš ï¸ ChÆ°a cÃ³ mÃ´ hÃ¬nh! HÃ£y huáº¥n luyá»‡n trÆ°á»›c.")


    # ğŸ†• Cáº­p nháº­t key cho canvas khi nháº¥n "Táº£i láº¡i"
    if "key_value" not in st.session_state:
        st.session_state.key_value = str(random.randint(0, 1000000))  

    if st.button("ğŸ”„ Táº£i láº¡i náº¿u khÃ´ng tháº¥y canvas"):
        st.session_state.key_value = str(random.randint(0, 1000000))  

    # âœï¸ Váº½ sá»‘
    canvas_result = st_canvas(
        fill_color="black",
        stroke_width=10,
        stroke_color="white",
        background_color="black",
        height=150,
        width=150,
        drawing_mode="freedraw",
        key=st.session_state.key_value,
        update_streamlit=True
    )

    if st.button("Dá»± Ä‘oÃ¡n sá»‘"):
        img = preprocess_canvas_image(canvas_result)

        if img is not None:
            st.image(Image.fromarray((img.reshape(28, 28) * 255).astype(np.uint8)), caption="áº¢nh sau xá»­ lÃ½", width=100)

            # Dá»± Ä‘oÃ¡n sá»‘
            prediction = model.predict(img)
            predicted_number = np.argmax(prediction, axis=1)[0]
            max_confidence = np.max(prediction)

            st.subheader(f"ğŸ”¢ Dá»± Ä‘oÃ¡n: {predicted_number}")
            st.write(f"ğŸ“Š Má»©c Ä‘á»™ tin cáº­y: {max_confidence:.2%}")

            # Hiá»ƒn thá»‹ báº£ng confidence score
            prob_df = pd.DataFrame(prediction.reshape(1, -1), columns=[str(i) for i in range(10)]).T
            prob_df.columns = ["Má»©c Ä‘á»™ tin cáº­y"]
            st.bar_chart(prob_df)

        else:
            st.error("âš ï¸ HÃ£y váº½ má»™t sá»‘ trÆ°á»›c khi báº¥m Dá»± Ä‘oÃ¡n!")

    
from datetime import datetime    
import streamlit as st
import mlflow
from datetime import datetime

def show_experiment_selector():
    st.title("ğŸ“Š MLflow")
    
    # Káº¿t ná»‘i vá»›i DAGsHub MLflow Tracking
    mlflow.set_tracking_uri("https://dagshub.com/huydfdcv/my-first-repo.mlflow")
    
    # Láº¥y danh sÃ¡ch táº¥t cáº£ experiments
    experiment_name = "MNIST Pseudo Labelling"
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"âŒ Experiment '{experiment_name}' khÃ´ng tá»“n táº¡i!")
        return

    st.subheader(f"ğŸ“Œ Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tráº¡ng thÃ¡i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**Vá»‹ trÃ­ lÆ°u trá»¯:** {selected_experiment.artifact_location}")

    # Láº¥y danh sÃ¡ch runs trong experiment
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("âš  KhÃ´ng cÃ³ runs nÃ o trong experiment nÃ y.")
        return

    st.write("### ğŸƒâ€â™‚ï¸ CÃ¡c Runs gáº§n Ä‘Ã¢y:")
    
    # Láº¥y danh sÃ¡ch run_name tá»« params
    run_info = []
    for _, run in runs.iterrows():
        run_id = run["run_id"]
        run_tags = mlflow.get_run(run_id).data.tags
        run_name = run_tags.get("mlflow.runName", f"Run {run_id[:8]}")  # Láº¥y tá»« tags
        run_info.append((run_name, run_id))
    
    # Táº¡o dictionary Ä‘á»ƒ map run_name -> run_id
    run_name_to_id = dict(run_info)
    run_names = list(run_name_to_id.keys())
    
    # Chá»n run theo run_name
    selected_run_name = st.selectbox("ğŸ” Chá»n má»™t run:", run_names)
    selected_run_id = run_name_to_id[selected_run_name]

    # Hiá»ƒn thá»‹ thÃ´ng tin chi tiáº¿t cá»§a run Ä‘Æ°á»£c chá»n
    selected_run = mlflow.get_run(selected_run_id)

    if selected_run:
        st.subheader(f"ğŸ“Œ ThÃ´ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tráº¡ng thÃ¡i:** {selected_run.info.status}")
        
        start_time_ms = selected_run.info.start_time  # Thá»i gian lÆ°u dÆ°á»›i dáº¡ng milliseconds
        if start_time_ms:
            start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S")
        else:
            start_time = "KhÃ´ng cÃ³ thÃ´ng tin"
        
        st.write(f"**Thá»i gian cháº¡y:** {start_time}")

        # Hiá»ƒn thá»‹ thÃ´ng sá»‘ Ä‘Ã£ log
        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### âš™ï¸ Parameters:")
            st.json(params)

        if metrics:
            st.write("### ğŸ“Š Metrics:")
            st.json(metrics)

        # Kiá»ƒm tra vÃ  hiá»ƒn thá»‹ dataset artifact
        dataset_path = f"{selected_experiment.artifact_location}/{selected_run_id}/artifacts/dataset.npy"
        st.write("### ğŸ“‚ Dataset:")
        st.write(f"ğŸ“¥ [Táº£i dataset]({dataset_path})")
    else:
        st.warning("âš  KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin cho run nÃ y.")

def Neural_Network():
    #st.title("ğŸš€ MLflow DAGsHub Tracking vá»›i Streamlit")
    
    if "mlflow_initialized" not in st.session_state:   
        DAGSHUB_MLFLOW_URI = "https://dagshub.com/huydfdcv/my-first-repo.mlflow"
        st.session_state['mlflow_url']=DAGSHUB_MLFLOW_URI
        mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)

        os.environ["MLFLOW_TRACKING_USERNAME"] = "huydfdcv"
        os.environ["MLFLOW_TRACKING_PASSWORD"] = "2CaXhRNYabm9fN3"
        st.session_state.mlflow_initialized = True
        mlflow.set_experiment("MNIST Pseudo Labelling")   
        
    
    
    # Táº¡o cÃ¡c tab vá»›i tiÃªu Ä‘á» tÆ°Æ¡ng á»©ng
    tab1, tab2, tab3 = st.tabs([
        "ğŸ§  Huáº¥n luyá»‡n",
        "ğŸ–¥ï¸ DEMO",
        "ğŸ”¥ MLflow"
    ])

    # Ná»™i dung tá»«ng tab
    with tab1:
        st.title("ğŸ§  Huáº¥n luyá»‡n Neural Network trÃªn MNIST")
        split_data()
        thi_nghiem()
    with tab2:
        du_doan()
    with tab3:
        show_experiment_selector()

if __name__ == "__main__":
    Neural_Network()